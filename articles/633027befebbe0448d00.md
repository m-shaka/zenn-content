---
title: "翻訳: Elmコンパイラの出力を改善する"
emoji: "🏎️"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["elm", "javascript"]
published: true
---
この記事は"[Improving Elm's compiler output](https://dev.to/robinheghan/improving-elm-s-compiler-output-5e1h)"を原著者の承諾を得た上で日本語に翻訳したものです。原著者はElmの開発チームの1人なので、記事で紹介されている変更が将来的に取り込まれる可能性は高いと思われます。

なお、脚注は全て訳者によるもので原文には存在しません。以下本文。

---
Elmは速い。
<!-- Elm is fast. -->

これはコンパイラに何か革新的なものがあるからではない。実際、Elmコンパイラはほとんど何の最適化も行っていない。
<!-- This is not because of any innovation in the compiler. In fact, the Elm compiler hardly does any optimization at all. -->

Elmが速いのはJavaScriptにコンパイルされるからだ。JavaScriptは、熱意と才能を携えた世界中のエンジニア達が10年以上にわたって最適化を続けてきたものだ。
<!-- Elm is fast because it compiles to Javascript, which dedicated and talented engineers from all over the globe have been optimizing for more than a decade. -->

しかしここで疑問がわく。Elmコンパイラはブラウザーが最適化しやすいJavaScriptを出力しているのだろうか？また、仮にそうでないならば、出力するJavaScriptを変更すればパフォーマンスは向上するのだろうか？
<!-- But here's a question: does the Elm compiler output Javascript which makes it easy for browsers to optimize it and, if not, is there any performance to gain by changing how the compiler outputs Javascript? -->

ちょっと覗いてみよう。
<!-- Let's have a look. -->

## 隠れクラス
<!-- ## Hidden classes -->
JavaScriptは動的言語だ。JavaScriptにおいて、オブジェクトはいつでも形状(shape)[^1]を変えることができる。変数やデータ構造はいつだって様々な型の様々な値を持つことが可能だ。しかし、現実には大抵のプログラムは割と静的な作りをしているし、ブラウザーも可能ならばそれを利用する。
<!-- Javascript is a dynamic language. Javascript allows objects to change in shape at any time. Variables and data structures can contain different values of different types at any time. In practice, however, most programs are fairly static and browsers try to take advantage of this. -->
[^1]: どんなフィールドを持つかということ。定訳があるかは不明。

Chromeではオブジェクトリテラルとクラスは形状として扱われる。プロパティが動的に追加・削除されるという具合に、オブジェクトやクラスの形状が変化するとChromeはそれを新しい形状と見なすし、それらを相互に変換しようとする。正格な形状を把握するのが難しい場合、Chromeはオブジェクトをハッシュマップとして扱うこともある（Elmの`Dict`のように）。私達はこれらの形状を隠れクラスと呼んでいる[^2]。
<!-- In Chrome, every object literal and class is seen as a shape. If the shape of an object or class changes, like a property being dynamicly added or removed, Chrome will see the resultant new shape and try to convert between them. In some cases, Chrome will just treat objects as hashmaps (kinda like Elm's Dict) if it has trouble figuring out the precise shape of something. We call these shapes for hidden classes. -->

[^2]: 主語はweなので「私達」と訳したが、"hidden class"自体はV8の開発サイドも使っている用語。

最もパフォーマンスに優れるのは、JavaScriptのコードが見たところ複数の異なる形状を一度に扱っていないときだ。幸運にもElmは静的言語なので、ほとんどいつもそうなっているはずだ。ただ、Elmが異なる形状を同じ型として作る場合もある。1つ例を見てみよう。
<!-- We get the best performance when our Javascript code doesn't seem to deal with many different shapes at a time. Fortunately, Elm is a static language so this should be pretty common. There is, however, a case where Elm does produce different shapes that can pass as the same type. Let's look at an example: -->

```elm
type Maybe a
  = Just a
  | Nothing
```

これはElmの`Maybe`の定義だ。これは次のようなJavaScriptにコンパイルされる（`--optimized`を使っている）。
<!-- This is how Elm's Maybe is defined. It is compiled into the following Javascript (using --optimized): -->

```js
var elm$core$Maybe$Just = function (a) {
    return {$: 0, a: a};
};

var elm$core$Maybe$Nothing = {$: 1};
```

読めばわかるように、`Just`と`Nothing`に対するJavaScriptのオブジェクトリテラルは形状が違っている。こうして`Maybe`を扱うJavaScriptのコードは、2つの異なる形状を取り扱えなければならなくなった。しかしこれはコストなのだろうか？
<!-- As you can see, the Javascript object literal for Just and Nothing has different shapes. As a result, every Javascript code which deals with Maybe has to be able to deal with two different shapes. But is that costly? -->

影響を測るために私が行ったことは2つ。
<!-- To measure the effect I've done two things: -->

1) パフォーマンスに差異が出ると期待してベンチマークを取り、2つのバージョンを作る。うち1つはオーバーヘッドを避けるため手で修正する。
<!-- 1) Make a benchmark which can hopefully pick up the performance difference, then make two versions where one is handcoded to avoid the overhead. -->
1) Nodeが出力するアセンブリを読む（NodeとChromeはどちらもJSエンジンとしてV8を使っている）
<!-- 2) Look at the assembly code which Node outputs (Node and Chrome uses the same JS engine, V8). -->

この実験のためのコードは[github](https://github.com/Skinney/elm-code-gen-experiments)で読める。
<!-- You can find the code for this experiment at github. -->

私はElm組み込みの`List`型に着目した。この型はほとんどのプログラムで使われているからだ。この部分でパフォーマンスを改善できれば、全てのElmユーザーが大きな恩恵にあずかることになる。
<!-- I've focused on Elm' built-in List type, as it's used in pretty much every program. A performance improvement here would be a big benefit to everyone who uses Elm. -->

次のベンチマークを見てみよう。
<!-- We'll be focusing on the following benchmark: -->

```elm
benchmark "int +" <|
  \_ -> foldl (+) 0 intList
```

単純な全要素の左畳み込みで、要素を全部を足し合わせている。ここでのパフォーマンスの変化は、リストをどれだけ速く走査できるかを示してくれる。理論的には、複数の隠れクラスを扱うことによるオーバーヘッドを取り除けばパフォーマンスは向上するはずだ。
<!-- Simply a left fold over all the elements, adding them together. A change in performance here will tell us how quickly we can iterate through a List, the theory being that removing any overhead dealing with multiple hidden classes should increase performance. -->

ベンチマークをコンパイルしよう。コンパイルされたJSを見ると、こんなコード片が見つかる。
<!-- We compile the benchmark. Looking through the compiled JS output, we can find this piece of code: -->

```js
var _List_Nil = { $: 0 };
function _List_Cons(hd, tl) { return { $: 1, a: hd, b: tl }; }
```

空リストはリストの要素とは違った見た目をしている（`List`の動きが気になるなら、[Elm Europe 2017](https://www.youtube.com/watch?v=mmiNobpx7eI)で詳しく説明したので見てほしい）。
<!-- The empty List looks different from a List element (if you're wondering how Lists work, I explained it decently well at Elm Europe 2017). -->

JSファイルをコピーし、こんなふうに修正する。
<!-- We copy the JS file, and make the following modificaiton: -->

```js
var _List_Nil = { $: 0, a: null, b: null };
function _List_Cons(hd, tl) { return { $: 1, a: hd, b: tl }; }
```

`List`はもはや（複数の形状の）多相[^3]ではない。
<!-- A List should no longer be polymorphic (of many shapes). -->
[^3]: ここでの「多相」は「1つの型で異なった複数の形状を使っている」というような意味で使われており、パラメトリック多相とか部分型付けなどとは無関係。詳しくは"Inline Caching"で検索するか参考文献を参照。

結果はこうだ。
<!-- The result: -->

- Firefox, 修正前: 75,843 ops/sec
- Firefox, 修正後: 84,549 ops/sec
- Safari, 修正前: 248,531 ops/sec
- Safari, 修正後: 248,530 ops/sec
- Chrome, 修正前: 294,434 ops/sec
- Chrome, 修正後: 302,569 ops/sec

つまり、Safariでは違いが無かったけれど、ChromeとFirefoxではかなりの改善が見られた。Firefoxでは~11%、Chromeでは~4%の改善だ。注意してもらいたいが、これはコンパイラで実装できることで、Elmのコードを変える必要は全くなく、アプリケーション開発者側は何も頑張る必要がないパフォーマンス向上なのである。
<!-- So, no difference in Safari, however both Chrome and Firefox see a pretty decent improvement: ~11% in Firefox, ~4% in Chrome. Keep in mind that this is something that can be implemented in the compiler, no Elm code would have to change, it's a performance improvement for no effort on the part of application developers. -->

次のスクリプトを実行すればV8が生成したコードも見られる。
<!-- We can also look at the code that V8 generates by running the following script: -->

```sh
node --print-opt-code --code-comments index.js > jit_log
```

修正無し版のベンチマークの`jit_log`を読むとこんな結果が見つかる。
<!-- By reading the jit_log for the benchmark run without modifications, we can see: -->

```
--- Optimized code ---
optimization_id = 1
source_position = 48049
kind = OPTIMIZED_FUNCTION
name = $List$foldl
stack_slots = 10
compiler = turbofan
address = 0x28bd2bd6e9a1
Body (size = 2292)
Instructions (size = 2012)
<Assembly code>
```

修正したコードのログはこちら。
<!-- While for the modified code we see -->

```
--- Optimized code ---
optimization_id = 0
source_position = 48067
kind = OPTIMIZED_FUNCTION
name = $List$foldl
stack_slots = 10
compiler = turbofan
address = 0x2081135eec01
Body (size = 1848)
Instructions (size = 1600)
<Assembly code>
```

期待通り、多相を扱う必要が無い場合の方が生成コードが少ない。
<!-- As expected, it generated less code when the code doesn't have to deal with polymorphism. -->

しかし、両方のログに残るある記述が私を戸惑わせてた。
<!-- There is, however, something in both of this logs which give me pause: -->

```
Inlined functions (count = 1)
 0x3f2705632551 <SharedFunctionInfo A2>
```

ログのこのセクションはいくつの関数がインライン化されたかを列挙している。今回のケースだと、関数の引数を評価する関数だけがインライン化されていた（この意味についてはすぐに説明する）。実はこれはそんなに驚くようなことではない。`foldl`内部には関数呼び出しは1つしかない。これはループの度に一度だけ実行される[^4]。中で呼ばれる関数は大抵同じものではないので、インライン化されていなくても不思議な話ではない。しかし、最適化された関数を見ていくとわかるように、インライン化されているのは引数を1つ取る関数（1引数関数とも呼ばれる）か、A2, A3, A4などと呼ばれる関数かのどちらかだけなのである。
<!-- This section of the log lists how many functions have been inlined. In this case, only a function which evaluates the passed in function has been inlined (I'll explain what this mean in a second). This isn't actually that surprising. foldl only contains a single function call, which is done once per loop. This function is usually never the same either, so it makes sense that it wasn't inlined. However, if you look at all the other functions that have been optimized, the only functions which are inlined are either functions which take a single argument (also called arity-1 functions) or functions called A2, A3, A4 etc. -->
[^4]: ここは`foldl`の[コンパイル結果](https://github.com/robinheghan/elm-code-gen-experiments/blob/master/2_inline/bench.js#L2349-L2367)を読むと話がはやい。

どういうことだろう？
<!-- What gives? -->

## インライン化[^5]
<!-- ## Inlining -->
[^5]: V8は頻繁に呼び出される関数を自動でインライン展開してくれる。ベンチマークでは同じ関数を膨大な回数呼び出すのでインライン展開されていてほしい、という前提があるように思われる。またこれは機械語レイヤーの話であり、ElmがJSのコードをインライン展開するという話ではないことには注意されたし。

関数呼び出しのインライン化（関数呼び出しをその関数の実装に置き換えること）はコンパイラができる最も重要な最適化の1つだ。これが重要であるのは、関数呼び出しが総じてハイコストであるから、というわけでは必ずしもない。むしろ、インライン化によってコンパイラはコードが何をしているかをよりよく理解し、それに基づいて最適化を実行できるようになるからだ。
<!-- Inlining function calls (replacing the function call with the implementation of the function) is one of the most important optimizations a compiler can make. This is not necessarily because function calls are all that expensive, but because it allows the compiler to better understand what the code does and perform optimizations based on that. -->

もう一度ベンチマークを見よう。
<!-- Let's look at our benchmark again: -->

```elm
benchmark "int +" <|
  \_ -> foldl (+) 0 intList
```

インライン化されなければこのコードは`foldl`を呼び出す。`foldl`はリストの各要素に対して関数を呼ぶループである。`foldl`はどんな関数でも受け付けるので、（たとえスタックに保存できたとしても）中間結果の数値は参照として保持され、関数呼び出しの度にメモリへのルックアップが走る[^4]。整数以外を畳み込むときなどはそうだが、中間結果が整数でない場合、オプティマイザーは全ての値を`foldl`の中で使えるハッシュマップのように扱う。
<!-- Without inlining, this would call the foldl function, which is a loop calling a function for every element in the list. Since foldl can accept any function, it would store the intermediary number value as a reference (even though it could be stored as a number on the stack), performing a lookup in memory each time the function is called. If we weren't storing ints as intermediary values, as it would be the case if we were folding over other things, the Javscript optimizer would likely treat all values as a generic hashmap inside of foldl. -->

しかし、インライン化されればこの関数は単なるjavascriptのループにコンパイルされる。そこには関数呼び出しが1つもない代わりに、ループ内で実際に使われている型に特化したコードが展開されているのだ。実際にはコンパイラは関数呼び出しを単相にはしないのだけどその恩恵をうけられる、みたいな話だ[^6]。
<!-- With inlining, however, this function is likely to be compiled down to a single javascript loop, without any function calls at all, and with specialized code for the types actually used in the loop. This is like getting the benefits of a monomorphising compiler, without actually having a monomorphishing compiler. -->
[^6]: 本文中の"polymorphic"や参考文献での"monomorphism"の使い方をみると勘違いしそう（訳者は思い切りした）だが、ここで"monomophising"は「多相で定義された関数の呼び出しを、呼び出し時の引数の型に特化したコードに変換する」という、人によってはよく慣れ親しんだ意味で使われている。[原著者が挙げてくれたコード例](https://dev.to/robinheghan/comment/1a2lf)を使って具体的に説明する。`listmap`は`(a -> b) -> List a -> List b`と型付けられる多相関数で、引数にどんな型が来るかはわからないとする。しかし"monomorphising compiler"は`listmap String.fromInt [ 1, 2, 3 ]`をIntやStringに最適化されたコードに変換してくれる。なお、訳文はこの理解のもとに言葉を補っている。

ではなぜ多くの関数がインライン化されないままなのか？そしてA2って一体何なんだ？
<!-- But why aren't many functions being inlined, and what are all these A2 things? -->

## カリー化
<!-- ## Currying -->
Elmにはカリー化という概念がある。以下の関数があるとする。
<!-- Elm has this concept of currying. Given the following function: -->

```elm
add : Int -> Int -> Int
add a b =
  a + b
```

こんな新しい関数を作ることが出来る。
<!-- You can create a new function like this: -->

```elm
add2 : Int -> Int
add2 =
  add 2
```

つまり、引数を全て渡して関数を呼び出せば実行され、一部のみ渡して呼び出せば足りない関数を受け取る新しい関数が返される。
<!-- So if you call a function with enough arguments, it will execute. If you call a function without all the arguments it requires, it returns a new function which accepts the missing arguments. -->

上の`add`関数はこんな感じにJSにコンパイルされる。
<!-- This is how the above add function is compiled to JS: -->

```js
function F(arity, fun, wrapper) {
  wrapper.a = arity;
  wrapper.f = fun;
  return wrapper;
}

function F2(fun) {
  return F(2, fun, function(a) { return function(b) { return fun(a,b); }; })

var author$project$Main$add = F2(function(a, b) {
  return a + b;
});
```

私達の`add`関数も他のElmの関数はどれも、あるオブジェクトにラップされている。このオブジェクトは元の関数、関数が期待する引数の数、そしてカリー化された関数からなる。関数呼び出しには`A2`が必要で、以下はその実装だ。
<!-- Our add function, as well as every other Elm function, is wrapped in an object which contains the original function, the arity that function expects, and a curried function. Calling the function has to be done with A2, which is implemented like this: -->

```js
function A2(fun, a, b) {
  return fun.a === 2 ? fun.f(a, b) : fun(a)(b);
}
```
A2はF2オブジェクトを受取り、受け取った関数が事実引数を2つ取るならばそれを直接呼び出す。そうでなければカリー化関数を部分適用する。
<!-- So A2 takes a F2 object, and calls the function directly if the provided function actually takes two arguments, or does a curried call if not. -->

javascriptエンジンから見ればこれは大きな問題だ。プログラム全体の解析（これはとてもコストが高い）が終わるまで、元の関数が呼び出されるのか、カリー化関数が呼び出されるのか知る術がないのだ。A2自体はインライン化できるが、それ以上は無理だ。
<!-- From the perspective of a javascript engine, this has a big problem: unless we do whole program analysis (which is too expensive) there's no way to know if the function itself should be called, or if it is to be called using currying. The A2 call itself can be inlined, but nothing more. -->

じゃあElmコンパイラをもっと賢くしたら？もしElmコンパイラが関数が求める引数の数を知っていれば、これを
<!-- But what if we made the Elm compiler smarter? If the Elm compiler knew how many arguments a function required, it could re-write this: -->

```js
A2(author$project$Main$add, 1, 2)
```

こう書き換えられる。
```js
author$project$Main$add.f(1, 2)
```

ベンチマークをコピーして、ベンチマークとそこから呼ばれる全ての関数呼び出しを手で修正する。
<!-- We make a copy of our benchmark, and make these changes by hand for every function call in our benchmark, and in the functions called by the benchmark. -->

今回焦点を当てるのは次の関数。
<!-- This time we're going to focus on the results for the following function: -->

```elm
benchmark "* 2" <|
  \_ -> map (\a -> a * 2) intList
```

結果はこうなった。
<!-- The result: -->

- Firefox, 修正前: 24,291 ops/sec
- Firefox, 修正後: 50,927 ops/sec
- Safari, 修正前: 35,723 ops/sec
- Safari, 修正後: 49,029 ops/sec
- Chrome, 修正前: 39,253 ops/sec
- Chrome, 修正後: 58,491 ops/sec

かなりよい。Firefoxでは2倍、ChromeとSafariでは~30%のパフォーマンス向上だ。
<!-- Pretty good. The performance in Firefox is doubled, while we're seeing ~30% improvements in Chrome and Safari. -->

修正前のコードのインライン化の結果はこう。
<!-- When looking at the inlining results of the unmodified code: -->

```
Inlined functions (count = 1)
 0x13f84c332341 <SharedFunctionInfo A2>
```

修正版ではいくらか変化が見られる。
<!-- We can see there's been some changes after the modifications: -->

```
Inlined functions (count = 5)
 0x1f31bec396e1 <SharedFunctionInfo $map>
 0x1f31bec395a9 <SharedFunctionInfo $foldr>
 0x1f31bec39541 <SharedFunctionInfo $foldrHelper>
 0x1f31bec32049 <SharedFunctionInfo F2>
 0x1f31bec31fe1 <SharedFunctionInfo F>
```

しかし、生成されたアセンブリを見ると多くの行に以下の記述が見られた。
<!-- However, looking over the generated assembly code I'm seeing a lot of lines containing the following: -->

```
call 0x1e5fad48abe0  (Call_ReceiverIsNotNullOrUndefined)
```

`someObject.f(args)`というかたちで関数を呼ぶとき、Chromeは`someObject`がnullやundefinedではないことを確かめなければならない。
<!-- When we're calling functions using someObject.f(args), Chrome has to make sure that someObject isn't null or undefined. -->

もう一度ベンチマークを取った。今度は`F`ラッパーから関数を取り出し直接呼ぶようにした。
<!-- I've run one more benchmark. This time I've placed functions outside of F wrappers, and call them directly. -->

結果。
<!-- The result: -->

- Firefox, 修正前: 50,927 ops/sec
- Firefox, 修正後: 59,632 ops/sec
- Safari, 修正前: 49,029 ops/sec
- Safari, 修正後: 43,695 ops/sec
- Chrome, 修正前: 58,491 ops/sec
- Chrome, 修正後: 63,619 ops/sec

ChromeとFirefoxではいくらかの速度向上が見られた。それぞれ~8%と~16%の改善だ。Safariは遅くなったが理由は不明。ベンチマークを何回か走らせたところ結果は大きくばらついたがこれも原因はよくわからない。
<!-- Chrome and Firefox see some nice speedups, ~16% for Firefox and ~8% for Chrome. Safari actually sees a slowdown but I don't know why. Re-running the benchmarks several times gives wildly different results, and I don't know what to make of that. -->

## 結論
<!-- ## Conclusion -->

Elmは速いがまだ高速化の余地はある。Elmコンパイラの出力を変えれば、Elmプログラムのパフォーマンスは有意なレベルで向上する。
<!-- Elm is fast, but there's still room to become faster. By making changes to how the Elm compiler outputs Javascript, we can increase the performance of Elm programs by a significant margin. -->

## 参考文献
<!-- ## Further reading -->

Chromeが如何にしてJavascriptを高速化しているかを知りたければ、以下の2つが私が知りうる中で最良だ。
<!-- If you want to know more on how Chrome makes Javascript fast, these are the two best resources I came across: -->

[Whats up with monomorphism](https://mrale.ph/blog/2015/01/11/whats-up-with-monomorphism.html)
[V8 Kinds](https://v8.dev/blog/elements-kinds)

---

翻訳は以上になります。Elmコンパイラの出力については以下のScrapboxにも情報を載せていく予定です。

https://scrapbox.io/read-elm-js/

最後に訳文のチェックや励ましなどでご協力いただいた方へスペシャルサンクス

- https://twitter.com/y047aka
- https://twitter.com/nikueaters
