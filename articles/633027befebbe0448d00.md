---
title: "[ç¿»è¨³]Elmã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã®å‡ºåŠ›ã‚’æ”¹å–„ã™ã‚‹"
emoji: "ğŸ‘‹"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["elm", "translation"]
published: false
---
Elmã¯é€Ÿã„ã€‚
<!-- Elm is fast. -->

ã“ã‚Œã¯ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã«ä½•ã‹é©æ–°çš„ãªã‚‚ã®ãŒã‚ã‚‹ã‹ã‚‰ã§ã¯ãªã„ã€‚å®Ÿéš›ã€Elmã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã¯ã»ã¨ã‚“ã©ä½•ã®æœ€é©åŒ–ã‚‚è¡Œã£ã¦ã„ãªã„ã€‚
<!-- This is not because of any innovation in the compiler. In fact, the Elm compiler hardly does any optimization at all. -->

ElmãŒé€Ÿã„ã®ã¯JavaScriptã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã‚‹ã‹ã‚‰ã ã€‚JavaScriptã¯ç†±æ„ã¨æ‰èƒ½ã‚’æºãˆãŸä¸–ç•Œä¸­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é”ãŒ10å¹´ä»¥ä¸Šã«ã‚ãŸã£ã¦æœ€é©åŒ–ã‚’ç¶šã‘ã¦ããŸã‚‚ã®ã ã€‚
<!-- Elm is fast because it compiles to Javascript, which dedicated and talented engineers from all over the globe have been optimizing for more than a decade. -->

ã—ã‹ã—ã“ã“ã§ç–‘å•ãŒã‚ãã€‚Elmã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã¯ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ãŒæœ€é©åŒ–ã—ã‚„ã™ã„JavaScriptã‚’å‡ºåŠ›ã—ã¦ã„ã‚‹ã®ã‹ï¼Ÿã¾ãŸã€ä»®ã«ãã†ã§ãªã„ãªã‚‰ã°ã€å‡ºåŠ›ã™ã‚‹JavaScriptã‚’å¤‰æ›´ã™ã‚Œã°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯å‘ä¸Šã™ã‚‹ã®ã‹ï¼Ÿ
<!-- But here's a question: does the Elm compiler output Javascript which makes it easy for browsers to optimize it and, if not, is there any performance to gain by changing how the compiler outputs Javascript? -->

ã¡ã‚‡ã£ã¨è¦—ã„ã¦ã¿ã‚ˆã†ã€‚
<!-- Let's have a look. -->

## éš ã‚Œã‚¯ãƒ©ã‚¹
<!-- ## Hidden classes -->
JavaScriptã¯å‹•çš„è¨€èªã ã€‚JavaScriptã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒã„ã¤ã§ã‚‚å½¢çŠ¶(shape)[^1]ã‚’å¤‰ãˆã‚‹ã“ã¨ã‚’è¨±ã—ã¦ã„ã‚‹ã€‚å¤‰æ•°ã‚„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¯ã„ã¤ã ã£ã¦æ§˜ã€…ãªå‹ã®æ§˜ã€…ãªå€¤ã‚’æŒã¤ã“ã¨ãŒå‡ºæ¥ã‚‹ã€‚ã—ã‹ã—ã€å®Ÿéš›ã«ã¯å¤§æŠµã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã‹ãªã‚Šé™çš„ãªä½œã‚Šã‚’ã—ã¦ã„ã‚‹ã—ã€ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ã‚‚ãã‚Œã‚’æ´»ç”¨ã—ã‚ˆã†ã¨ã™ã‚‹ã€‚
<!-- Javascript is a dynamic language. Javascript allows objects to change in shape at any time. Variables and data structures can contain different values of different types at any time. In practice, however, most programs are fairly static and browsers try to take advantage of this. -->
[^1]: è¨³æ³¨: ã©ã‚“ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŒã¤ã‹ã¨ã„ã†ã“ã¨ã€‚å®šè¨³ãŒã‚ã‚‹ã‹ã¯ä¸æ˜ã€‚

Chromeã§ã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒ†ãƒ©ãƒ«ã¨ã‚¯ãƒ©ã‚¹ã¯å½¢çŠ¶ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹ã€‚ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚„ã‚¯ãƒ©ã‚¹ã®å½¢çŠ¶ãŒå¤‰ã‚ã‚‹ã¨ã€ã¾ã‚‹ã§ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ãŒå‹•çš„ã«è¿½åŠ ãƒ»å‰Šé™¤ã•ã‚Œã‚‹ã‹ã®ã‚ˆã†ã«ã€Chromeã¯çµæœã‚’æ–°ã—ã„å½¢çŠ¶ã¨è¦‹ãªã—å¤‰æ›ã—ã‚ˆã†ã¨ã™ã‚‹ã€‚æ­£æ ¼ãªå½¢çŠ¶ã‚’ç†è§£ã™ã‚‹ã®ãŒé›£ã—ã„ã¨ã€Chromeã¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒãƒƒã‚·ãƒ¥ãƒãƒƒãƒ—ã¨ã—ã¦æ‰±ã†ã“ã¨ã‚‚ã‚ã‚‹ï¼ˆElmã®`Dict`ã®ã‚ˆã†ã«ï¼‰ã€‚æˆ‘ã€…ã¯ã“ã‚Œã‚‰ã®å½¢çŠ¶ã‚’éš ã‚Œã‚¯ãƒ©ã‚¹ã¨å‘¼ã‚“ã§ã„ã‚‹ã€‚
<!-- In Chrome, every object literal and class is seen as a shape. If the shape of an object or class changes, like a property being dynamicly added or removed, Chrome will see the resultant new shape and try to convert between them. In some cases, Chrome will just treat objects as hashmaps (kinda like Elm's Dict) if it has trouble figuring out the precise shape of something. We call these shapes for hidden classes. -->

æœ€ã‚‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å„ªã‚Œã‚‹ã®ã¯ã€JavaScriptã®ã‚³ãƒ¼ãƒ‰ãŒè¦‹ãŸã¨ã“ã‚è¤‡æ•°ã®ç•°ãªã‚‹å½¢çŠ¶ã‚’ä¸€åº¦ã«æ‰±ã£ã¦ã„ãªã„å ´åˆã ã€‚å¹¸é‹ã«ã‚‚Elmã¯é™çš„è¨€èªãªã®ã§ã€ã»ã¨ã‚“ã©ã„ã¤ã‚‚ãã†ãªã£ã¦ã„ã‚‹ã¯ãšã ã€‚ãŸã ã€ElmãŒåˆ¥ã€…ã®å½¢çŠ¶ã‚’åŒã˜å‹ã¨ã—ã¦ä½œã‚‹å ´åˆã‚‚ã‚ã‚‹ã€‚ä¾‹ã‚’è¦‹ã‚ˆã†ã€‚
<!-- We get the best performance when our Javascript code doesn't seem to deal with many different shapes at a time. Fortunately, Elm is a static language so this should be pretty common. There is, however, a case where Elm does produce different shapes that can pass as the same type. Let's look at an example: -->

```elm
type Maybe a
  = Just a
  | Nothing
```

ã“ã‚Œã¯Elmã®`Maybe`ã®å®šç¾©ã ã€‚ã“ã‚Œã¯æ¬¡ã®ã‚ˆã†ãªJavaScriptã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã‚‹ï¼ˆ`--optimized`ã‚’ä½¿ã£ã¦ã„ã‚‹ï¼‰ã€‚
<!-- This is how Elm's Maybe is defined. It is compiled into the following Javascript (using --optimized): -->

```js
var elm$core$Maybe$Just = function (a) {
    return {$: 0, a: a};
};

var elm$core$Maybe$Nothing = {$: 1};
```

èª­ã‚ã°ã‚ã‹ã‚‹ã‚ˆã†ã«ã€`Just`ã¨`Nothing`ã«å¯¾ã™ã‚‹JavaScriptã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒ†ãƒ©ãƒ«ã¯å½¢çŠ¶ãŒç•°ãªã‚‹ã€‚`Maybe`ã‚’æ‰±ã†JavaScriptã®ã‚³ãƒ¼ãƒ‰ã¯ã€2ã¤ã®ç•°ãªã‚‹å½¢çŠ¶ã‚’å–ã‚Šæ‰±ãˆãªã‘ã‚Œã°ãªã‚‰ãªããªã£ãŸã€‚ã—ã‹ã—ã“ã‚Œã¯ã‚³ã‚¹ãƒˆãªã®ã ã‚ã†ã‹ï¼Ÿ
<!-- As you can see, the Javascript object literal for Just and Nothing has different shapes. As a result, every Javascript code which deals with Maybe has to be able to deal with two different shapes. But is that costly? -->

å½±éŸ¿ã‚’æ¸¬ã‚‹ãŸã‚ã«ç§ãŒè¡Œã£ãŸã“ã¨ã¯2ã¤ã€‚
<!-- To measure the effect I've done two things: -->

1) ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«å·®ç•°ãŒå‡ºã‚‹ã¨æœŸå¾…ã—ã¦ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å–ã‚Šã€2ã¤ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½œã‚‹ã€‚ã†ã¡1ã¤ã¯ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’é¿ã‘ã‚‹ãŸã‚æ‰‹ã§ä¿®æ­£ã™ã‚‹ã€‚
<!-- 1) Make a benchmark which can hopefully pick up the performance difference, then make two versions where one is handcoded to avoid the overhead. -->
1) NodeãŒåãã‚¢ã‚»ãƒ³ãƒ–ãƒªã‚’èª­ã‚€ï¼ˆNodeã¨Chromeã¯ã©ã¡ã‚‰ã‚‚JSã‚¨ãƒ³ã‚¸ãƒ³ã¨ã—ã¦V8ã‚’ä½¿ã£ã¦ã„ã‚‹ï¼‰
<!-- 2) Look at the assembly code which Node outputs (Node and Chrome uses the same JS engine, V8). -->

ã“ã®å®Ÿé¨“ã®ãŸã‚ã®ã‚³ãƒ¼ãƒ‰ã¯[github](https://github.com/Skinney/elm-code-gen-experiments)ã§èª­ã‚ã‚‹ã€‚
<!-- You can find the code for this experiment at github. -->

ç§ã¯Elmçµ„ã¿è¾¼ã¿ã®`List`å‹ã«ç„¦ç‚¹ã‚’å½“ã¦ãŸã€‚ã“ã®å‹ã¯ã»ã¨ã‚“ã©ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹ã‹ã‚‰ã ã€‚ã“ã®éƒ¨åˆ†ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ”¹å–„ã§ãã‚Œã°å…¨ã¦ã®Elmãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¤§ããªæ©æµã«ã‚ãšã‹ã‚‹ã“ã¨ã«ãªã‚‹ã€‚
<!-- I've focused on Elm' built-in List type, as it's used in pretty much every program. A performance improvement here would be a big benefit to everyone who uses Elm. -->

æ¬¡ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’è¦‹ã¦ã¿ã‚ˆã†ã€‚
<!-- We'll be focusing on the following benchmark: -->

```elm
benchmark "int +" <|
  \_ -> foldl (+) 0 intList
```

å˜ç´”ãªå…¨è¦ç´ ã®å·¦ç•³ã¿è¾¼ã¿ã§ã€å…¨éƒ¨ã‚’è¶³ã—åˆã‚ã›ã¦ã„ã‚‹ã€‚ã“ã“ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®å¤‰åŒ–ã¯ã€ãƒªã‚¹ãƒˆã‚’ã©ã‚Œã ã‘é€Ÿãèµ°æŸ»ã§ãã‚‹ã‹ã‚’ç¤ºã—ã¦ãã‚Œã‚‹ã€‚ç†è«–çš„ã«ã¯ã€è¤‡æ•°ã®éš ã‚Œã‚¯ãƒ©ã‚¹ã‚’æ‰±ã†ã“ã¨ã«ã‚ˆã‚‹ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å–ã‚Šé™¤ã‘ã°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯å‘ä¸Šã™ã‚‹ã¯ãšã ã€‚
<!-- Simply a left fold over all the elements, adding them together. A change in performance here will tell us how quickly we can iterate through a List, the theory being that removing any overhead dealing with multiple hidden classes should increase performance. -->

ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã‚ˆã†ã€‚ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚ŒãŸJSã‚’è¦‹ã‚‹ã¨ã€ã“ã‚“ãªã‚³ãƒ¼ãƒ‰ç‰‡ãŒè¦‹ã¤ã‹ã‚‹ã€‚
<!-- We compile the benchmark. Looking through the compiled JS output, we can find this piece of code: -->

```js
var _List_Nil = { $: 0 };
function _List_Cons(hd, tl) { return { $: 1, a: hd, b: tl }; }
```

ç©ºãƒªã‚¹ãƒˆã¯ãƒªã‚¹ãƒˆã®è¦ç´ ã¨è¦‹ãŸç›®ãŒç•°ãªã‚‹ï¼ˆ`List`ã®å‹•ããŒæ°—ã«ãªã‚‹ãªã‚‰ã€[Elm Europe 2017](https://www.youtube.com/watch?v=mmiNobpx7eI)ã§ãŒã£ã¤ã‚Šèª¬æ˜ã—ãŸã®ã§è¦‹ã¦ã»ã—ã„ï¼‰ã€‚
<!-- The empty List looks different from a List element (if you're wondering how Lists work, I explained it decently well at Elm Europe 2017). -->

JSãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã—ã€ã“ã‚“ãªãµã†ã«ä¿®æ­£ã™ã‚‹ã€‚
<!-- We copy the JS file, and make the following modificaiton: -->

```js
var _List_Nil = { $: 0, a: null, b: null };
function _List_Cons(hd, tl) { return { $: 1, a: hd, b: tl }; }
```

`List`ã¯ã‚‚ã¯ã‚„ï¼ˆè¤‡æ•°ã®å½¢çŠ¶ã®ï¼‰å¤šç›¸ã§ã¯ãªã„ã€‚
<!-- A List should no longer be polymorphic (of many shapes). -->

çµæœã¯ã“ã†ã ã€‚
<!-- The result: -->

- Firefox, before modification: 75,843 ops/sec
- Firefox, after modification: 84,549 ops/sec
- Safari, before modification: 248,531 ops/sec
- Safari, after modification: 248,530 ops/sec
- Chrome, before modification: 294,434 ops/sec
- Chrome, after modification: 302,569 ops/sec

ã¤ã¾ã‚Šã€Safariã§ã¯é•ã„ãŒç„¡ã‹ã£ãŸã‘ã‚Œã©ã€Chromeã¨Firefoxã§ã¯ã‹ãªã‚Šã®æ”¹å–„ãŒè¦‹ã‚‰ã‚ŒãŸã€‚Firefoxã§ã¯~11%ã€Chromeã§ã¯~4%ã®æ”¹å–„ã ã€‚æ³¨æ„ã—ã¦ã‚‚ã‚‰ã„ãŸã„ãŒã€ã“ã‚Œã¯ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã§å®Ÿè£…ã§ãã‚‹ã“ã¨ã§ã€Elmã®ã‚³ãƒ¼ãƒ‰ã‚’å¤‰ãˆã‚‹å¿…è¦ã¯ãªãã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºè€…å´ã«ã¯ä½•ã®åŠ´åŠ›ã‚‚ç„¡ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šãªã®ã§ã‚ã‚‹ã€‚
<!-- So, no difference in Safari, however both Chrome and Firefox see a pretty decent improvement: ~11% in Firefox, ~4% in Chrome. Keep in mind that this is something that can be implemented in the compiler, no Elm code would have to change, it's a performance improvement for no effort on the part of application developers. -->

æ¬¡ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã™ã‚Œã°V8ãŒç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰ã‚‚è¦‹ã‚‰ã‚Œã‚‹ã€‚
<!-- We can also look at the code that V8 generates by running the following script: -->

```sh
node --print-opt-code --code-comments index.js > jit_log
```

ä¿®æ­£ç„¡ã—ç‰ˆã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã®`jit_log`ã‚’èª­ã‚€ã¨ã“ã‚“ãªçµæœãŒè¦‹ã¤ã‹ã‚‹ã€‚
<!-- By reading the jit_log for the benchmark run without modifications, we can see: -->

```
--- Optimized code ---
optimization_id = 1
source_position = 48049
kind = OPTIMIZED_FUNCTION
name = $List$foldl
stack_slots = 10
compiler = turbofan
address = 0x28bd2bd6e9a1
Body (size = 2292)
Instructions (size = 2012)
<Assembly code>
```

ä¿®æ­£ã—ãŸã‚³ãƒ¼ãƒ‰ã®ã¯ã“ã¡ã‚‰ã€‚
<!-- While for the modified code we see -->

```
--- Optimized code ---
optimization_id = 0
source_position = 48067
kind = OPTIMIZED_FUNCTION
name = $List$foldl
stack_slots = 10
compiler = turbofan
address = 0x2081135eec01
Body (size = 1848)
Instructions (size = 1600)
<Assembly code>
```

æœŸå¾…é€šã‚Šã€å¤šç›¸ã‚’æ‰±ã†å¿…è¦ãŒç„¡ã„å ´åˆã®æ–¹ãŒç”Ÿæˆã‚³ãƒ¼ãƒ‰ãŒå°‘ãªã„ã€‚
<!-- As expected, it generated less code when the code doesn't have to deal with polymorphism. -->

ã—ã‹ã—ã€ä¸¡æ–¹ã®ãƒ­ã‚°ã«æ®‹ã‚‹ã‚ã‚‹è¨˜è¿°ãŒç§ã‚’æˆ¸æƒ‘ã‚ã›ã¦ãŸã€‚
<!-- There is, however, something in both of this logs which give me pause: -->

```
Inlined functions (count = 1)
 0x3f2705632551 <SharedFunctionInfo A2>
```

<!-- TODO: å¾Œã§è¦‹ã‚‹ -->
ãƒ­ã‚°ã®ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯é–¢æ•°ãŒã„ãã¤ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã•ã‚ŒãŸã‹ã‚’åˆ—æŒ™ã—ã¦ã„ã‚‹ã€‚ã“ã®å ´åˆã€é–¢æ•°ã®å¼•æ•°ã‚’è©•ä¾¡ã™ã‚‹é–¢æ•°ã ã‘ãŒã‚¤ãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã•ã‚Œã¦ã„ãŸï¼ˆã“ã®æ„å‘³ã«ã¤ã„ã¦ã¯ã™ãã«èª¬æ˜ã™ã‚‹ï¼‰ã€‚ã“ã‚Œã¯åˆ¥ã«é©šãã‚ˆã†ãªã“ã¨ã§ã¯ãªã„ã€‚`foldl`ã¯ã€ãƒ«ãƒ¼ãƒ—ã‚’é€šã—ã¦ä¸€å›ã ã‘å®Ÿè¡Œã•ã‚Œã‚‹1ã¤ã®é–¢æ•°å‘¼ã³å‡ºã—ã ã‘ã‚’å«ã‚€ã€‚This function is usually never the same either, so it makes sense that it wasn't inlined. ã—ã‹ã—ã€æœ€é©åŒ–ã•ã‚ŒãŸä»–ã®é–¢æ•°ã‚’è¦‹ã¦ã„ãã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ã€ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³åŒ–ã•ã‚Œã¦ã„ã‚‹ã®ã¯å¼•æ•°ã‚’1ã¤å–ã‚‹é–¢æ•°ï¼ˆ1å¼•æ•°é–¢æ•°ã¨ã‚‚å‘¼ã°ã‚Œã‚‹ï¼‰ã‹ã€A2, A3, A4ãªã©ã¨å‘¼ã°ã‚Œã‚‹é–¢æ•°ã‹ã®ã©ã¡ã‚‰ã‹ã ã‘ãªã®ã§ã‚ã‚‹ã€‚
<!-- This section of the log lists how many functions have been inlined. In this case, only a function which evaluates the passed in function has been inlined (I'll explain what this mean in a second). This isn't actually that surprising. foldl only contains a single function call, which is done once per loop. This function is usually never the same either, so it makes sense that it wasn't inlined. However, if you look at all the other functions that have been optimized, the only functions which are inlined are either functions which take a single argument (also called arity-1 functions) or functions called A2, A3, A4 etc. -->

ã©ã†ã„ã†ã“ã¨ã ã‚ã†ï¼Ÿ
<!-- What gives? -->

## Inlining
Inlining function calls (replacing the function call with the implementation of the function) is one of the most important optimizations a compiler can make. This is not necessarily because function calls are all that expensive, but because it allows the compiler to better understand what the code does and perform optimizations based on that.

Let's look at our benchmark again:

```elm
benchmark "int +" <|
  \_ -> foldl (+) 0 intList
```

Without inlining, this would call the foldl function, which is a loop calling a function for every element in the list. Since foldl can accept any function, it would store the intermediary number value as a reference (even though it could be stored as a number on the stack), performing a lookup in memory each time the function is called. If we weren't storing ints as intermediary values, as it would be the case if we were folding over other things, the Javscript optimizer would likely treat all values as a generic hashmap inside of foldl.

With inlining, however, this function is likely to be compiled down to a single javascript loop, without any function calls at all, and with specialized code for the types actually used in the loop. This is like getting the benefits of a monomorphising compiler, without actually having a monomorphishing compiler.

But why aren't many functions being inlined, and what are all these A2 things?

## Currying
Elm has this concept of currying. Given the following function:

```elm
add : Int -> Int -> Int
add a b =
  a + b
```

You can create a new function like this:

```elm
add2 : Int -> Int
add2 =
  add 2
```

So if you call a function with enough arguments, it will execute. If you call a function without all the arguments it requires, it returns a new function which accepts the missing arguments.

This is how the above add function is compiled to JS:

```js
function F(arity, fun, wrapper) {
  wrapper.a = arity;
  wrapper.f = fun;
  return wrapper;
}

function F2(fun) {
  return F(2, fun, function(a) { return function(b) { return fun(a,b); }; })

var author$project$Main$add = F2(function(a, b) {
  return a + b;
});
```

Our add function, as well as every other Elm function, is wrapped in an object which contains the original function, the arity that function expects, and a curried function. Calling the function has to be done with A2, which is implemented like this:

```js
function A2(fun, a, b) {
  return fun.a === 2 ? fun.f(a, b) : fun(a)(b);
}
```

So A2 takes a F2 object, and calls the function directly if the provided function actually takes two arguments, or does a curried call if not.

From the perspective of a javascript engine, this has a big problem: unless we do whole program analysis (which is too expensive) there's no way to know if the function itself should be called, or if it is to be called using currying. The A2 call itself can be inlined, but nothing more.

But what if we made the Elm compiler smarter? If the Elm compiler knew how many arguments a function required, it could re-write this:
```js
A2(author$project$Main$add, 1, 2)
```

into
```js
author$project$Main$add.f(1, 2)
```

We make a copy of our benchmark, and make these changes by hand for every function call in our benchmark, and in the functions called by the benchmark.

This time we're going to focus on the results for the following function:

```elm
benchmark "* 2" <|
  \_ -> map (\a -> a * 2) intList
```

The result:

- Firefox, before modification: 24,291 ops/sec
- Firefox, after modification: 50,927 ops/sec
- Safari, before modification: 35,723 ops/sec
- Safari, after modification: 49,029 ops/sec
- Chrome, before modification: 39,253 ops/sec
- Chrome, after modification: 58,491 ops/sec

Pretty good. The performance in Firefox is doubled, while we're seeing ~30% improvements in Chrome and Safari.

When looking at the inlining results of the unmodified code:

```
Inlined functions (count = 1)
 0x13f84c332341 <SharedFunctionInfo A2>
```

We can see there's been some changes after the modifications:

```
Inlined functions (count = 5)
 0x1f31bec396e1 <SharedFunctionInfo $map>
 0x1f31bec395a9 <SharedFunctionInfo $foldr>
 0x1f31bec39541 <SharedFunctionInfo $foldrHelper>
 0x1f31bec32049 <SharedFunctionInfo F2>
 0x1f31bec31fe1 <SharedFunctionInfo F>
```

However, looking over the generated assembly code I'm seeing a lot of lines containing the following:

```
call 0x1e5fad48abe0  (Call_ReceiverIsNotNullOrUndefined)
```

When we're calling functions using someObject.f(args), Chrome has to make sure that someObject isn't null or undefined.

I've run one more benchmark. This time I've placed functions outside of F wrappers, and call them directly.

The result:

- Firefox, before modification: 50,927 ops/sec
- Firefox, after modification: 59,632 ops/sec
- Safari, before modification: 49,029 ops/sec
- Safari, after modification: 43,695 ops/sec
- Chrome, before modification: 58,491 ops/sec
- Chrome, after modification: 63,619 ops/sec

Chrome and Firefox see some nice speedups, ~16% for Firefox and ~8% for Chrome. Safari actually sees a slowdown but I don't know why. Re-running the benchmarks several times gives wildly different results, and I don't know what to make of that.

## Conclusion
Elm is fast, but there's still room to become faster. By making changes to how the Elm compiler outputs Javascript, we can increase the performance of Elm programs by a significant margin.

## Further reading
If you want to know more on how Chrome makes Javascript fast, these are the two best resources I came across:

Whats up with monomorphism
V8 Kinds
